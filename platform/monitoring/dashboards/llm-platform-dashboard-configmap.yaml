apiVersion: v1
kind: ConfigMap
metadata:
  name: llm-platform-dashboard
  namespace: monitoring
  labels:
    grafana_dashboard: "1"
data:
  llm-platform-dashboard.json: |
    {
      "uid": "llm-platform",
      "title": "LLM Platform Dashboard",
      "tags": ["llm", "poc", "platform"],
      "timezone": "",
      "schemaVersion": 39,
      "version": 1,
      "refresh": "5s",
      "time": { "from": "now-6h", "to": "now" },
      "timepicker": {
        "refresh_intervals": ["5s", "10s", "30s", "1m", "5m", "15m"],
        "time_options": ["5m", "15m", "30m", "1h", "6h", "12h", "24h"]
      },
      "templating": {
        "list": [
          {
            "type": "datasource",
            "name": "datasource",
            "label": "Data source",
            "query": "prometheus",
            "current": { "selected": true, "text": "Prometheus", "value": "Prometheus" }
          }
        ]
      },
      "panels": [
        {
          "type": "timeseries",
          "title": "Requests per second",
          "gridPos": { "h": 10, "w": 12, "x": 0, "y": 0 },
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "targets": [
            {
              "refId": "A",
              "expr": "sum(rate(llm_requests_total[1m]))",
              "legendFormat": "RPS"
            }
          ],
          "fieldConfig": { "defaults": { "unit": "reqps" }, "overrides": [] }
        },
        {
          "type": "timeseries",
          "title": "Average Inference Duration (seconds)",
          "gridPos": { "h": 10, "w": 12, "x": 12, "y": 0 },
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "targets": [
            {
              "refId": "A",
              "expr": "sum(rate(llm_inference_seconds_sum[1m])) / sum(rate(llm_inference_seconds_count[1m]))",
              "legendFormat": "Average latency"
            }
          ],
          "fieldConfig": { "defaults": { "unit": "s" }, "overrides": [] }
        },
        {
          "type": "timeseries",
          "title": "P95 Inference Duration (seconds)",
          "gridPos": { "h": 10, "w": 12, "x": 0, "y": 10 },
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "targets": [
            {
              "refId": "A",
              "expr": "histogram_quantile(0.95, sum(rate(llm_inference_seconds_bucket[1m])) by (le))",
              "legendFormat": "p95 latency"
            }
          ],
          "fieldConfig": { "defaults": { "unit": "s" }, "overrides": [] }
        },
        {
          "type": "timeseries",
          "title": "Errors per second",
          "gridPos": { "h": 10, "w": 12, "x": 12, "y": 10 },
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "targets": [
            {
              "refId": "A",
              "expr": "sum(rate(llm_errors_total[1m]))",
              "legendFormat": "Errors/sec"
            }
          ],
          "fieldConfig": { "defaults": { "unit": "ops" }, "overrides": [] }
        }
      ]
    }