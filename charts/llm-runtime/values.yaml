replicaCount: 1

image:
  repository: ollama/ollama
  tag: latest
  pullPolicy: IfNotPresent

model:
  name: tinyllama

service:
  type: ClusterIP
  port: 11434

runtime:
  host: llm-runtime
  port: 11434

persistence:
  enabled: true
  size: 5Gi
  accessMode: ReadWriteOnce

resources:
  requests:
    cpu: 500m
    memory: 1Gi
  limits:
    cpu: 1000m
    memory: 2Gi

autoscaling:
  enabled: true

  minReplicas: 1
  maxReplicas: 2
  targetCPUUtilizationPercentage: 70

  behavior:
    scaleUp:
      stabilizationWindowSeconds: 0
      percent: 100
      periodSeconds: 15

    scaleDown:
      stabilizationWindowSeconds: 60
      percent: 50
      periodSeconds: 30